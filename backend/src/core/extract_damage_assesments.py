"""
LangChain Agent for extracting damage assessment information from text.
This agent processes text containing damage information (people, infrastructure, facilities)
and extracts structured JSON data.
"""

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from pydantic import BaseModel, Field
from typing import List, Optional
import os
from dotenv import load_dotenv
from src.config import config
load_dotenv()

import httpx

import json
def format_blocks_group_source(data):
    text_blocks = data['text_blocks']
    references = {ref['index']: ref for ref in data['references']}
    lines = []
    i = 0
    while i < len(text_blocks):
        block = text_blocks[i]
        # Heading
        if block['type'] == 'heading':
            lines.append(f"### {block['snippet']}\n")
            # Thu th·∫≠p t·∫•t c·∫£ block thu·ªôc m·ª•c n√†y (paragraph + list) cho ƒë·∫øn heading ti·∫øp theo
            content_lines = []
            source_indexes = set()
            j = i + 1
            while j < len(text_blocks) and text_blocks[j]['type'] != 'heading':
                b = text_blocks[j]
                if b['type'] == 'paragraph':
                    content_lines.append(b['snippet'])
                    if 'reference_indexes' in b:
                        source_indexes.update(b['reference_indexes'])
                elif b['type'] == 'list':
                    for item in b['list']:
                        content_lines.append(f"- {item['snippet']}")
                    if 'reference_indexes' in b:
                        source_indexes.update(b['reference_indexes'])
                j += 1
            # Th√™m n·ªôi dung
            lines.extend(content_lines)
            # Th√™m d√≤ng ngu·ªìn 1 l·∫ßn cho c·∫£ m·ª•c
            if source_indexes:
                srcs = []
                for r in sorted(source_indexes):
                    if r in references:
                        srcs.append(f"{references[r]['source']} ({references[r]['link']})")
                lines.append("\nNgu·ªìn: " + ", ".join(srcs))
            lines.append("")  # d√≤ng tr·ªëng gi·ªØa c√°c heading
            i = j
        else:
            i += 1
    return "\n".join(lines)

async def fetch_damage_data(url: str) -> dict:
    async with httpx.AsyncClient() as client:
        response = await client.get(url)
        response.raise_for_status()
        response = response.json()
    return response


class CasualtyStats(BaseModel):
    """Th·ªëng k√™ th∆∞∆°ng vong"""
    deaths: Optional[int] = Field(default=None, description="S·ªë ng∆∞·ªùi t·ª≠ vong")
    missing: Optional[int] = Field(default=None, description="S·ªë ng∆∞·ªùi m·∫•t t√≠ch")
    injured: Optional[int] = Field(default=None, description="S·ªë ng∆∞·ªùi b·ªã th∆∞∆°ng")


class PropertyDamage(BaseModel):
    """Thi·ªát h·∫°i v·ªÅ t√†i s·∫£n"""
    houses_damaged: Optional[int] = Field(default=None, description="S·ªë nh√† b·ªã h∆∞ h·ªèng/s·∫≠p/t·ªëc m√°i")
    houses_flooded: Optional[int] = Field(default=None, description="S·ªë nh√† b·ªã ng·∫≠p")
    boats_damaged: Optional[int] = Field(default=None, description="S·ªë t√†u thuy·ªÅn b·ªã h∆∞ h·∫°i/ch√¨m")
    description: Optional[str] = Field(default=None, description="M√¥ t·∫£ ng·∫Øn g·ªçn 4-5 t·ª´")


class InfrastructureDamage(BaseModel):
    """Thi·ªát h·∫°i v·ªÅ c∆° s·ªü h·∫° t·∫ßng"""
    roads_damaged: Optional[int] = Field(default=None, description="S·ªë tuy·∫øn ƒë∆∞·ªùng b·ªã h∆∞ h·∫°i/s·∫°t l·ªü")
    schools_damaged: Optional[int] = Field(default=None, description="S·ªë tr∆∞·ªùng h·ªçc b·ªã h∆∞ h·∫°i")
    hospitals_damaged: Optional[int] = Field(default=None, description="S·ªë b·ªánh vi·ªán/tr·∫°m y t·∫ø b·ªã h∆∞ h·∫°i")
    description: Optional[str] = Field(default=None, description="M√¥ t·∫£ ng·∫Øn g·ªçn 4-5 t·ª´")


class AgriculturalDamage(BaseModel):
    """Thi·ªát h·∫°i v·ªÅ n√¥ng nghi·ªáp"""
    crop_area_damaged_ha: Optional[float] = Field(default=None, description="Di·ªán t√≠ch c√¢y tr·ªìng b·ªã h∆∞ h·∫°i (ha)")
    livestock_lost: Optional[int] = Field(default=None, description="S·ªë gia s√∫c/gia c·∫ßm ch·∫øt")
    aquaculture_damaged_ha: Optional[float] = Field(default=None, description="Di·ªán t√≠ch nu√¥i tr·ªìng th·ªßy s·∫£n b·ªã h·∫°i (ha)")
    description: Optional[str] = Field(default=None, description="M√¥ t·∫£ ng·∫Øn g·ªçn 4-5 t·ª´")


class DamageAssessment(BaseModel):
    """Model for complete damage assessment - T·ªëi ∆∞u cho dashboard"""
    casualties: Optional[CasualtyStats] = Field(default=None, description="Th·ªëng k√™ th∆∞∆°ng vong")
    property: Optional[PropertyDamage] = Field(default=None, description="Thi·ªát h·∫°i t√†i s·∫£n")
    infrastructure: Optional[InfrastructureDamage] = Field(default=None, description="Thi·ªát h·∫°i c∆° s·ªü h·∫° t·∫ßng")
    agriculture: Optional[AgriculturalDamage] = Field(default=None, description="Thi·ªát h·∫°i n√¥ng nghi·ªáp")
    
    total_economic_loss_vnd: Optional[float] = Field(default=None, description="T·ªïng thi·ªát h·∫°i kinh t·∫ø (t·ª∑ ƒë·ªìng)")
    summary: Optional[str] = Field(default=None, description="T√≥m t·∫Øt 1 c√¢u ng·∫Øn g·ªçn")
    sources: Optional[List[str]] = Field(default=None, description="Danh s√°ch t·∫•t c·∫£ c√°c ngu·ªìn th√¥ng tin ƒë√£ s·ª≠ d·ª•ng")


class DamageExtractionAgent:
    """Agent for extracting damage assessment information from text"""
    
    def __init__(self, model_name: str = "gemini-2.5-flash", temperature: float = 0):
        """
        Initialize the damage extraction agent
        
        Args:
            model_name: Gemini model name to use (e.g., gemini-2.0-flash-exp, gemini-1.5-pro, gemini-1.5-flash)
            temperature: Temperature for model generation (0 = deterministic)
        """
        self.llm = ChatGoogleGenerativeAI(
            model=model_name,
            temperature=temperature,
            google_api_key=config.GOOGLE_API_KEY
        )
        
        # Setup output parser
        self.parser = JsonOutputParser(pydantic_object=DamageAssessment)
        
        # Create prompt template
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", """B·∫°n l√† chuy√™n gia ph√¢n t√≠ch thi·ªát h·∫°i thi√™n tai cho dashboard hi·ªán ƒë·∫°i.

üéØ NHI·ªÜM V·ª§: 
- VƒÉn b·∫£n c√≥ th·ªÉ ch·ª©a NHI·ªÄU NGU·ªíN KH√ÅC NHAU v·ªõi s·ªë li·ªáu kh√°c nhau
- T·ªîNG H·ª¢P, ƒê·ªêI CHI·∫æU c√°c ngu·ªìn v√† ch·ªçn s·ªë li·ªáu ƒë√°ng tin c·∫≠y nh·∫•t
- Tr√≠ch xu·∫•t S·ªê LI·ªÜU v√† LIST T·∫§T C·∫¢ NGU·ªíN ƒë√£ s·ª≠ d·ª•ng

üìä C·∫§U TR√öC ƒê·∫¶U RA:

1Ô∏è‚É£ casualties (TH∆Ø∆†NG VONG):
   - deaths: S·ªë ng∆∞·ªùi ch·∫øt (s·ªë nguy√™n, VD: 6)
   - missing: S·ªë ng∆∞·ªùi m·∫•t t√≠ch (s·ªë nguy√™n, VD: 2)
   - injured: S·ªë ng∆∞·ªùi b·ªã th∆∞∆°ng (s·ªë nguy√™n, VD: 26)
   
2Ô∏è‚É£ property (T√ÄI S·∫¢N):
   - houses_damaged: S·ªë nh√† h∆∞ h·ªèng (VD: 10000)
   - houses_flooded: S·ªë nh√† ng·∫≠p (VD: 5000)
   - boats_damaged: S·ªë t√†u thuy·ªÅn h∆∞ h·∫°i (VD: 9)
   - description: M√¥ t·∫£ ng·∫Øn 4-5 t·ª´ (VD: "H∆°n 10.000 nh√† h∆∞ h·ªèng")

3Ô∏è‚É£ infrastructure (C∆† S·ªû H·∫† T·∫¶NG):
   - roads_damaged: S·ªë tuy·∫øn ƒë∆∞·ªùng (VD: 15)
   - schools_damaged: S·ªë tr∆∞·ªùng h·ªçc (VD: 20)
   - hospitals_damaged: S·ªë b·ªánh vi·ªán/tr·∫°m y t·∫ø (VD: 5)
   - description: M√¥ t·∫£ ng·∫Øn 4-5 t·ª´ (VD: "ƒê∆∞·ªùng s·∫°t l·ªü, m·∫•t ƒëi·ªán")

4Ô∏è‚É£ agriculture (N√îNG NGHI·ªÜP):
   - crop_area_damaged_ha: Di·ªán t√≠ch c√¢y tr·ªìng (ha) (VD: 11200.0)
   - livestock_lost: S·ªë gia s√∫c/gia c·∫ßm (VD: 5000)
   - aquaculture_damaged_ha: Di·ªán t√≠ch th·ªßy s·∫£n (ha) (VD: 200.0)
   - description: M√¥ t·∫£ ng·∫Øn 4-5 t·ª´ (VD: "11.200 ha l√∫a ng·∫≠p")

5Ô∏è‚É£ total_economic_loss_vnd:
   - T·ªïng thi·ªát h·∫°i (t·ª∑ ƒë·ªìng): "13.000 t·ª∑" -> 13000.0

6Ô∏è‚É£ summary: T√≥m t·∫Øt 1 c√¢u ng·∫Øn

7Ô∏è‚É£ sources: DANH S√ÅCH T·∫§T C·∫¢ C√ÅC NGU·ªíN
   - List ƒê·∫¶Y ƒê·ª¶ C√ÅC ƒê∆Ø·ªúNG LINK/URL ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p trong vƒÉn b·∫£n
   - VD: ["https://nhandan.vn/...", "https://vnexpress.net/...", "https://laodong.vn/..."]
   - Tr√≠ch xu·∫•t CH√çNH X√ÅC URL G·ªêC t·ª´ vƒÉn b·∫£n

üîë QUY T·∫ÆC TR√çCH XU·∫§T:
‚úÖ Tr√≠ch xu·∫•t T·∫§T C·∫¢ S·ªê LI·ªÜU c√≥ trong vƒÉn b·∫£n (n·∫øu c√≥)
‚úÖ "H∆°n 100" -> 100 | "√çt nh·∫•t 6" -> 6 | "Kho·∫£ng 26" -> 26
‚úÖ LIST T·∫§T C·∫¢ C√ÅC ƒê∆Ø·ªúNG LINK/URL v√†o tr∆∞·ªùng sources
   - Tr√≠ch xu·∫•t CH√çNH X√ÅC URL ƒë·∫ßy ƒë·ªß t·ª´ vƒÉn b·∫£n
   - VD: "https://nhandan.vn/bao-so-13-gay-thiet-hai..."
   - N·∫øu c√≥ nhi·ªÅu URL, list h·∫øt t·∫•t c·∫£
‚úÖ Kh√¥ng c√≥ th√¥ng tin: ƒê·ªÉ null
‚úÖ M√¥ t·∫£ (description) ph·∫£i NG·∫ÆN G·ªåN 4-5 t·ª´, c√≥ th·ªÉ ch·ª©a s·ªë li·ªáu
‚ùå KH√îNG ƒëo√°n s·ªë li·ªáu khi kh√¥ng c√≥ th√¥ng tin
‚ùå KH√îNG vi·∫øt m√¥ t·∫£ d√†i d√≤ng

{format_instructions}"""),
            ("user", "{input_text}")
        ])
        
        # Create the chain
        self.chain = self.prompt | self.llm | self.parser
        
    def extract(self, text: str) -> dict:
        """
        Extract damage assessment from text
        
        Args:
            text: Input text containing damage information
            
        Returns:
            Dictionary containing structured damage assessment
        """
        result = self.chain.invoke({
            "input_text": text,
            "format_instructions": self.parser.get_format_instructions()
        })
        return result
    
    def extract_with_metadata(self, text: str, storm_id: str = None) -> dict:
        """
        Extract damage assessment with additional metadata
        
        Args:
            text: Input text containing damage information
            storm_id: Storm identifier
            
        Returns:
            Dictionary containing structured damage assessment with metadata
        """
        result = self.extract(text)
        
        # Add metadata
        result["metadata"] = {
            "storm_id": storm_id,
            "extraction_timestamp": __import__("datetime").datetime.now().isoformat()
        }
        
        return result
    
    async def extract_and_save_to_db(self, text: str, storm_id: str, 
                                     session) -> dict:
        """
        Extract damage assessment and save to database
        
        Args:
            text: Input text containing damage information
            storm_id: Storm identifier
            session: AsyncSession for database operations
            
        Returns:
            Dictionary containing saved damage assessment with metadata
        """
        from datetime import datetime
        from src.damage.model import damage_assessments
        
        # Extract damage information
        result = self.extract(text)
        
        # Prepare data for database
        detail = result.copy()
        extraction_time = datetime.now()
        
        # Save to database
        db_damage = await damage_assessments.create_damage_assessment(
            session=session,
            storm_id=storm_id,
            detail=detail,
            time=extraction_time.strftime("%d-%m-%Y %H:%M")
        )
        
        # Return result with database ID
        return {
            "id": db_damage.id,
            "storm_id": db_damage.storm_id,
            "detail": result,
            "time": db_damage.time.isoformat(),
            "created_at": db_damage.created_at.isoformat(),
            "message": "Damage assessment saved to database successfully"
        }


async def main():
    from src.config import config
    from src.database import AsyncSessionLocal
    """Example usage"""
    # Sample text (example damage report)
    parameters = {
        "engine": "google_ai_mode",
        "q": "th·ªëng k√™ thi·ªát h·∫°i do b√£o s·ªë 13 g√¢y ra t·∫°i Vi·ªát Nam cho ƒë·∫øn th·ªùi ƒëi·ªÉm hi·ªán t·∫°i theo nh·ªØng ti√™u ch√≠ sau: Thi·ªát h·∫°i v·ªÅ ng∆∞·ªùi(s·ªë ng∆∞·ªùi m·∫•t t√≠ch, b·ªã th∆∞∆°ng, t·ª≠ vong), Thi·ªát h·∫°i v·ªÅ nh√† c·ª≠a t√†i s·∫£n, thi·ªát h·∫°i v·ªÅ h·∫° t·∫ßng kinh t·∫ø, thi·ªát h·∫°i v·ªÅ n√¥ng nghi·ªáp s·∫£n xu·∫•t,  thi·ªát h·∫°i v·ªÅ m√¥i tr∆∞·ªùng v√† x√£ h·ªôi.",
        "api_key": config.SERPAPI_API_KEY
    }
    url = "https://serpapi.com/search.json"
    
    url = f"{url}?engine={parameters['engine']}&q={parameters['q']}&api_key={parameters['api_key']}"
    data = await fetch_damage_data(url)
    sample_text = format_blocks_group_source(data)
    # Initialize agent
    agent = DamageExtractionAgent()
    
    # Extract damage information
    print("Extracting damage assessment from text...")
    print("=" * 80)
    
    # Create database session and save
    async with AsyncSessionLocal() as session:
        async with session.begin():
            result = await agent.extract_and_save_to_db(
                text=sample_text,
                storm_id="2025305N10138",
                session=session
            )
    
    print(json.dumps(result, ensure_ascii=False, indent=2))



if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
